---
title: "02 Analysis"
date: "Last update: `r Sys.Date()`"
output:
  html_document:
    theme: paper
    highlight: kate
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: false
    number_sections: true
---
<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
  background-color: #00d188;
  border-color: #00d188;
}

body {
  font-family: montserrat;
  color: #444444;
  font-size: 14px;
}

h1 {
  font-weight: bold;
  font-size: 28px;
}

h1.title {
  font-size: 30px;
  color: #00d188;
}

h2 {
  font-size: 24px;
}

h3 {
  font-size: 18px;
}
</style>

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.showtext = TRUE)
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",", small.mark = ",", scientific = F)
})
```


Google is said to have the most accurate search engine (X% market share). We wanted to test how accurate the other main search engines (Bing, DuckDuckGo, and Yahoo) are compared to Google.

We analysed 60k search results from each search engine and came up with some interesting insights.

# Summary of insights

1. DuckDuckGo is the most accurate search engine when compared to Google. 
Google's #1 search result was found in DuckDuckGo's top 10 67.3% of the time. 
Bing is close with 66.3% and Yahoo worse at 62.2%.

2. For all search engines, we see that accuracy slightly improves for high 
volume, with gains between 1.5% and 2% when comparing volume of more and less than 10k.

3. The accuracy of the search engines differs by category. Real Estate, Travel & Tourism, and Retailers & General Merchandise are more accurate across _all_ search engines. While Apparel, Beauty & Personal Care, and Home & Garden are less accurate.

4. Accuracy is better for single word searches and for long searches.

5. The top results of Googles's competitors are much more similar between themselves than similar to Google's.

6. The different search engines feature in different amounts big domains such as amazon in their top result.

7. Searches that tend to yield results predominantly linking to a specific domain (domain specific), OR non
domain specific at all, show higher accuracy on average.

8. In more than half of the cases in any search engine, google's top result is
   found in position 1 to 3.
   
9. Accuracy varies on average depending on the domain extension of google's top
result.

# Research questions

1. Bing and DuckDuck are more accurate (~75%) than Yahoo (66%) when compared to Google [DONE]
  - Top 10 is more frequently used to look at search results [DONE]

2. The higher the search volume the more accurate the search result [DONE]

3. The accuracy of the search engines differs by category. Real Estate, Travel & Tourism, and Retailers & General Merchandise are more accurate across all search engines. While Apparel, Beauty & Personal Care, and Home & Garden are less accurate. These trends are similar across all search engines but there are specific categories like Health where Yahoo is particularly less accurate. [DONE]
  - Split categories into further sub levels (if we have sufficient data) [DONE]
  - Split categories by search volume) [DONE]
  
4. The longer the keyword used in the search the more accurate the result. This could be because the longer the keyword, the more specific the search query. [DONE]
  - Look into # of words

5. How similar are the rankings between search engines? E.g. is Google’s top 10 exactly the same as DuckDuck [DONE]

6. For results that produce a lot of the same domain, what is their accuracy? e.g. results that return lots of amazon links. We could look at domain accuracy in general as well [DONE]

7. What is the average distance to Google #1 search result? [DONE]

8. What can we learn from the description or titles? To brainstorm [TO DO ?]

See here an example example articles we did in the past  to get an idea for the end result and the type of findings we´re looking for: https://backlinko.com/Google-ctr-stats; https://backlinko.com/page-speed-stats



```{r load_and_setup, echo = T}
library(tidyverse) # package used for data wrangling
# options(dplyr.summarise.inform = F)
theme_set(theme_minimal() +
            theme(plot.title = element_text(size = 15)))
# "datasets_for_report.Rdata" is built by the following commented calls
# source(here::here("scripts/01_build_light_dataset.R"))
# source(here::here("scripts/02_build_datasets_for_report.R"))
load(here::here("proc_data/datasets_for_report.Rdata"))
```

# Analysis

## How accurate are the other search engines?

We developed an accuracy measure that counts how many times a search engines results contains Google's #1 result in their top 10. 

If the search engine contained Google's #1 result for all of their keywords their accuracy would be 100%. While if they did not, their accuracy would be 0%.

We show below the accuracy for each search engine using the top 10  as well as the top 20 and top 30 results.

We see that Yahoo is fairly behind both competitors and DuckDuckGo has a slight edge over Bing.


```{r, echo = T}
accuracy_by_se
```

For the rest of the report, unless stated otherwise, accuracy is computed by considering the top 10 results only.

## Monthly search volume

The sample of 60k search keywords were chosen so we got a fairly even split across different search volumes. 

```{r, echo = T}
monthly_search_volume
```

We show below how search volume affects the accuracy of the search engines,
considering the top 10, 20 or 30 results.

We see an improvement for volumes over 10K searches per month.

```{r, echo = T}
accuracy_by_se_and_vol %>% 
  ggplot(aes(monthly_search_volume_level, y = accuracy, colour = search_engine,
             group = search_engine)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword's Monthly Search Volume", 50),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Monthly Search Volume",
       y = "Search Engine Accuracy") +
  facet_wrap(vars(grp), ncol = 3)
```



## Keyword categories

Each of the keywords comes with categories (or tags). It's possible for keywords to belong to more than one category. The sample of 60k keywords was drawn randomly so we don't expect to have an equal amount in each category. 

The most common categories are News, Media & Publications, Arts & Entertainment, Business & Industrial, and Hobbies & Leisure.

```{r, echo = T}
category1_counts %>% 
  ggplot(aes(x = keyword_category, y = n)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_comma()) +

  labs(title = "# of Keywords by Category",
       x = "Keyword Category",
       y = NULL)
```

Deeper levels of categories are available, nested into the main categories,
we show below the breakdown of the level 2 and 3 categories.

```{r, echo = T}
category2_counts %>% 
  ggplot(aes(x = keyword_category, y = n)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_comma()) +

  labs(title = "# of Keywords by Category (level 2)",
       x = "Keyword Category",
       y = NULL)

category3_counts %>% 
  ggplot(aes(x = keyword_category, y = n)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_comma()) +

  labs(title = "# of Keywords by Category (level 3)",
       x = "Keyword Category",
       y = NULL)
  
```

The following chart shows that there is significant variance in accuracy depending on what category the keyword belongs too. Real Estate, Travel & Tourism, Retailers & General Merchandise, and Dining & Nightlife are the four most accurate categories across all the search engines (between 67% and 75%). While Home & Garden and Apparel are least accurate (between 55% and 61%).

Yahoo is also particularly less accurate in a couple of categories. For example, in Health Yahoo is 60% accurate (vs ~67% for the other two search engines). Similarly for Food & Groceries, and Beauty & Personal Care.

```{r, echo = T}
accuracy_by_se_and_category %>%
  ggplot(aes(x = keyword_category, y = accuracy,
             group = search_engine, colour = search_engine)) +
  geom_point() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Category", 30),
       # subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Keyword Category",
       y = "Search Engine Accuracy")
```

We reproduce this chart for the 10 biggest subcategories of level 2 and 3.

```{r, echo = T}
accuracy_by_se_and_category_2 %>%
  ggplot(aes(x = keyword_category, y = accuracy,
             group = search_engine, colour = search_engine)) +
  geom_point() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Category (level 2)", 30),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Keyword Category",
       y = "Search Engine Accuracy")

accuracy_by_se_and_category_3 %>%
  ggplot(aes(x = keyword_category, y = accuracy,
             group = search_engine, colour = search_engine)) +
  geom_point() +
  coord_flip() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Category (level 3)", 30),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Keyword Category",
       y = "Search Engine Accuracy")
```

Finally we offer a breakdown of the accuracy by main category and volume category.

We see that volume can make a big difference in some cases, for instance for
Health related keywords Bing and DuckDuck become much more accurate as volume increases.

We see also that Real Estate related searches give the most accurate results accross categories at lower volume.

```{r, echo = T}
accuracy_by_se_category_and_vol %>%
  ggplot(aes(x = keyword_category, y = accuracy,
             group = search_engine, colour = search_engine)) +
  geom_point() +
  coord_flip() +
  facet_wrap(vars(monthly_search_volume_level)) +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Category", 30),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Keyword Category",
       y = "Search Engine Accuracy")
```

Below we show, both for small and medium volume (resp. 500-1000 and 1000-10000),
5 examples of Real Estate keywords for which we found the same url on the top 
for every search engine.

```{r}
real_estate_examples_small_volume[c("keyword", "url")]

real_estate_examples_medium_volume[c("keyword", "url")]
```

## Number of words

Most keywords (search terms) have between 2 and 4 words. 
There are also 29 search terms that have at least 10 words. 
For example `what are the first ten amendments to the constitution called` and 
`how long does it take to become a pediatric nurse`.

```{r, echo = T}
kw_length_counts %>% 
  ggplot(aes(x = keyword_length, y = n)) +
  geom_col() +
  scale_x_continuous(breaks = seq(0, 10, 1)) +
  labs(title = "Keywords by # of Words",
       y = "# of Keywords",
       x = "# of Words in Keyword") +
  scale_y_continuous(labels = scales::label_comma())
```

For all three search engines, the search terms with only one word are the most
accurate, but we observe a "U" shape curve as longer keywords show more accurate 
results than medium length ones. 

On average accuracy for length 1 keywords is about 5% higher than for length 2,
and this difference is bigger for high volumes.

There might be two forces at play here, on one hand single word searches are more straightforward,
so we can expect search engines to converge more on them, and on the other hand
long keywords are more precise, so the pool of potential targets decreases with
the length of the search and long searches tend to converge over search engines too.

Searching for a brand name for instance, we expect to find the official website 
on the first result on all search engines, and searching for a blog article by typing
its full title we expect all search engines to propose it first as well.


```{r, echo = T}
accuracy_by_se_and_kw_length %>%
  ggplot(aes(keyword_length, y = accuracy, colour = search_engine,
             group = search_engine)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Length", 50),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Keyword Length in Words",
       y = "Search Engine Accuracy")

accuracy_by_se_vol_and_kw_length %>%
  ggplot(aes(keyword_length, y = accuracy, colour = search_engine,
             group = search_engine)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Keyword Length", 50),
       subtitle = "Top 10 - breakdown by volume level",
       colour = "Search Engine", 
       x = "Keyword Length in Words",
       y = "Search Engine Accuracy") +
  facet_wrap(vars(monthly_search_volume_level), ncol=3)
```

Below we show, both for single word searches and long searches,
5 examples for which we found the same url on the top 
for every search engine.

We see that the single word searches are either technical words, linking to
wikipedia definitions, or brand names , linking to their official webpage.

Long searches are more specific, for instance one long search links to a blog
article titled almost like the search, the 
format "best pizza in san diego little italy" is taylored for yelp and all the
search engines agree easily on the result to put at the top.

```{r}
short_kw_examples
long_kw_examples
```


## How similar are the rankings between search engines?

We define similarity between two search engines as the fraction of results (identified by url) that
we find in both top 10 results of the pair.

We see below that on average 71% of top 10 results on yahoo can be also found in the top 10 of Bing,
making them the most similar pair.

Google is very dissimilar to other search engines, especially Yahoo, its shares only
29% of top 10 results wit the latter.

```{r}
similarity %>%
  ggplot() +
  aes(descr, similarity, fill = search_engine2 == "Google") %>%
  geom_col() + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 30)) +
  labs(title = "Similarity between top 10 results of search engine pairs",
       x = NULL,
       y = "Average similarity") +
  scale_y_continuous(labels = scales::label_percent()) 
```

We show below the same chart but this time considering only the similarity between
top 3. We see overall that top3 results are more similar than top 10 results.
It makes sense as the higher we are on the page the less random should be the results,
and those should converge between search engines.

```{r}
similarity_3 %>%
  ggplot() +
  aes(descr, similarity, fill = search_engine2 == "Google") %>%
  geom_col() + 
  theme(legend.position = "none", axis.text.x = element_text(angle = 30)) +
  labs(title = "Similarity between top 3 results of search engine pairs",
       x = NULL,
       y = "Average similarity") +
  scale_y_continuous(labels = scales::label_percent()) 
```

## Top domains

We take a look at the top 10 domains featured in 1st position of Google searches
and see for which proportion of keyword they come up on top.

We see that search engines vary sensibly in which domain they put on top.

* Wikipedia is huge for all engines, but is featured significantly more by
  Google and Yahoo
* Amazon is less featured by Google than by its competitors.
* Trip Advisor is twice more featured by Google than its competitors
* weather.com is more than twice more featured by competitors

```{r}
top_domains %>%
  ggplot(aes(domain, pct, fill = search_engine)) +
  geom_col(position = "dodge") + 
  theme(axis.text.x = element_text(angle = 30)) +
  labs(title = "Prevalence of big domains in searches",
       x = "domain",
       y = "share of presence in top spot") +
  scale_y_continuous(labels = scales::label_percent()) 
```

We reproduce the analysis considering the whole top 10 results rather than only
the top result.

* We lose the wikipedia bias for Google when we look at the full top 10
* homedepot.com is featured 3 times more by Google in its top 10.

```{r}
top_domains_10 %>%
  ggplot(aes(domain, pct, fill = search_engine)) +
  geom_col(position = "dodge") + 
  theme(axis.text.x = element_text(angle = 30)) +
  labs(title = "Prevalence of big domains in searches",
       x = "domain",
       y = "share of presence in top spot") +
  scale_y_continuous(labels = scales::label_percent()) 
```

## Domain specificity

We define the domain specificity of a keyword as the number of top 10 Google results 
that feature the dominant domain of this top 10. For instance a research that returns
3 ebay results, 5 amazon results, and 2 other results, would be dominated by amazon, 
so would be considered "amazon specific", and would be attributed a domain specificity of 5.

We observe a U shape curve here too, searches that are very domain specific, or not at all,
show the most accuracy. It might be that moderate domain specificity is a symptom
of an unclear search, while very high domain specificity shows that the search
was more targetted.

```{r}

domain_specificity_by_kw %>%
  count(domain_specificity_grouped) %>%
  ggplot(aes(domain_specificity_grouped, n)) +
  geom_col() +
  geom_text(aes(label = n), nudge_y = 700) +
  ggtitle("breakdown of domain specificity in our sample") 

accuracy_by_se_and_spec %>%
  ggplot(aes(domain_specificity_grouped, y = accuracy, colour = search_engine,
             group = search_engine)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = str_wrap("Search Engine Accuracy by Domain Specificity", 50),
       subtitle = "Top 10",
       colour = "Search Engine", 
       x = "Domain specificity",
       y = "Search Engine Accuracy")
```

## At what position is Google's first result ?

We take a look at the position at which we find the first Google result in the results
of the competitors.

The most likely position of the first Google result is 1st. For every search engine,
around 35% of keywords will have Google's first result on top. 

For every search engine, in 12% of the cases, the the first Google result is found in second position.

The second most likely position is that it's not found at all in the top 30.

A fair amount of google first results are not found at all by other search engines,
at least not in the top 30, so we cannot compute a mean position, but we see
that for every other search engine,  we find google's top results in the top 3 
more than half of the time.


```{r}
google1_positions %>%
  mutate(google1_position = factor(google1_position, c(1:30, NA), c(1:30, "not found"), exclude = NULL)) %>%
  ggplot(aes(google1_position, pct, fill = search_engine )) +
  geom_col(position = "dodge") +
  scale_y_continuous(labels = scales::label_percent()) +
  labs(title = "Distribution of position of top Google result among rankings of other search engines",
      x = "position",
      y = "amount (%)") +
  theme(axis.text.x = element_text(angle = 30))
```

```{r}
# computing the mean position is not possible because a fair amount of Google
# first urls are just not found, so the mean is undefined, we can compute the 
# median position however, by assuming unfound is Inf
median_google1_positions
```


## How does accuracy vary with domain extension

We look at the domain extension of the domain of google's first search and
observe how it affects accuracy.

We see that accuracy is much better when google's top result points to a ".info" or
".org" website than when it points to a ".uk" or ".ca" website.

```{r}
accuracy_by_se_and_domain_ext %>%
  ggplot(aes(ext, accuracy, fill = search_engine)) +
  geom_col(position = "dodge") +
  labs(title = "Accuracy by search engine and domain extension", 
       subtitle = "Based on most common domain extensions in Google's top results",
       x = "domain extension",
       y = "accuracy")
```

